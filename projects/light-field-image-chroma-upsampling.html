<!DOCTYPE html><html><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-X60PNPCW5T"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-X60PNPCW5T');
</script><title>Petingo</title><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"><link rel="stylesheet" href="/assets/css/main.css"><link rel="icon" href="/images/logo.png"><noscript><link rel="stylesheet" href="/assets/css/noscript.css"></noscript><script src="https://cdn.jsdelivr.net/npm/typeit@7.0.4/dist/typeit.min.js"></script></head><body class="is-preload"><div id="wrapper"><header id="header"><div class="inner"><a class="logo" href="/"><span class="symbol"><img src="/images/logo.png" alt=""></span><span class="title">Petingo</span></a><nav><ul><li><a href="#menu">Menu</a></li></ul></nav></div></header><nav id="menu"><h2>Menu</h2><ul><li><a href="/">Home</a></li><li><a href="/about.html">About</a></li><li><a href="https://ghost.petingo.cc/">Blog</a></li></ul></nav><div id="main"><div class="inner"><div id="article"><h1>Light Field Image Chroma Upsampling</h1><p><b>(This page is under construction, some parts may be missing)</b></p><span class="image main"><img src="/images/light-field-image-chroma-upsampling/main.png"></span><h2>Introduction </h2><p> Light Field Image (LFI) is a special kind of image that contains information on the light's direction in the 3D space.
In LFI, an image can be seen as an array of many sub-images, each of which is a view of the scene from a different direction.
Many applications can be carried out with LFI, such as re-focusing, depth estimation, and 3D reconstruction.
However, since LFI is captured by placing a micro-lens array between the main lens and the sensor, the resolution of the LFI is sacrificed.
As a result, it became an important issue to enhance the resolution of LFI.</p><p> Since our lab has done much research related to chroma upsampling, we decided to also work from this aspect.
Moreover, although there is some research on upsampling LFIs, none of them mentioned the part of chroma upsampling.
From our perspective, if we can find a way to improve the chroma upsampling method of LFIs,
we can probably replace Bayer Filter with another color-filter array to capture more luminance information, and further, enhance the image quality.
In this paper, we proposed a CNN-based chroma upsampling method for LFIs, which takes a YUV420 LFI as input and outputs a YUV444 LFI.</p><h2>Image Compress Pipeline</h2><p> First, I would like to give a brief introduction to the image compress pipeline.
Normally, when a computer shows an image on the screen, it uses RGB format to display it.
However, since human eyes are more sensitive to luminance than chroma, we can drop some chroma information without losing too much quality.
Thus, we can convert RGB into YUV format and subsample the UV channel, where Y and UV store luminance and chroma information, respectively.
When we want to display the image, we can simply upsample the UV channel and convert it back to RGB format.</p><span class="image fit"> <img src="/images/light-field-image-chroma-upsampling/image-compression-pipeline.png"></span><h2>Model</h2><p> We designed a CNN-based model to perform chroma upsampling.
The model takes a YUV420 LFI with 5x5 angular resolution as input and outputs the "residual" of the UV channels,
which will be added to the bicubic upsampled UV channel in the end.</p><span class="image fit"> <img src="/images/light-field-image-chroma-upsampling/model-arch.png"></span><p>(+Model explanation)</p><p> The SAS block refers to Spatial-Angular Separable convolution block, in which the convolution is applied to both spatial and angular dimensions.
Initially, the axis of a LFI is (Angular X, Angular Y, Spatial X, Spatial Y, channels) and the convolution is applied to the first two dimensions, which is the angular axis.
After the convolution, the axis of the LFI is permuted as (spatial X, spatial Y, Angular X, Angular Y, channels) to apply the convolution to the spatial axis.</p><span class="image fit"> <img src="/images/light-field-image-chroma-upsampling/SAS-block.png"></span><h2>Training Pipeline</h2><span class="image fit"> <img src="/images/light-field-image-chroma-upsampling/training-pipeline.png"></span><h2>Results</h2><p>Here, we use Peak Signal-to-Noise Ration (PSNR) to evaluate the performance of our model,
where the definition of PSNR is as follows:</p><span class="image fit"> <img src="/images/light-field-image-chroma-upsampling/PSNR.png"></span><p> Since there are no previous research on chroma upsampling of LFIs, we compare our model with the conventional chroma upsampling method, Bicubic and Bilinear.
From the results, we can see that our model outperforms the other two methods, with 1.24 dB and 2.22 dB on average.</p><table style="text-align:center"><tr><th style="width: 5em;">#LFI</th><th>Proposed</th><th>Bicubic </th><th>Bilinear </th></tr><tr> <td><span style="font-weight: 600;">1</span></td><td><span style="font-weight: 600;">43.8130</span></td><td>41.9761</td><td>41.3578</td></tr><tr><td><span style="font-weight: 600;">2</span></td><td> <span style="font-weight: 600;">42.941</span></td><td>40.9295</td><td>39.0823</td></tr><tr><td><span style="font-weight: 600;">3</span></td><td> <span style="font-weight: 600;">43.3452</span></td><td>42.9033</td><td>42.0984</td></tr><tr> <td><span style="font-weight: 600;">4</span></td><td> <span style="font-weight: 600;">41.651</span></td><td>40.9344</td><td>39.8863</td></tr><tr><td><span style="font-weight: 600;">5</span></td><td> <span style="font-weight: 600;">39.0649</span></td><td>36.9544</td><td>34.8554</td></tr><tr> <td><span style="font-weight: 600;">6</span></td><td>47.9479</td><td>48.4569</td><td> <span style="font-weight: 600;">49.5385 </span></td></tr><tr> <td><span style="font-weight: 600;">7</span></td><td> <span style="font-weight: 600;">43.5154</span></td><td>41.1901</td><td>40.2849</td></tr><tr><td><span style="font-weight: 600;">8</span></td><td> <span style="font-weight: 600;">44.3984</span></td><td>43.4254</td><td>41.8508</td></tr><tr><td><span style="font-weight: 600;">Average </span></td><td> <span style="font-weight: 600;">43.3346</span></td><td>42.0963</td><td>41.1193   </td></tr></table><h2>Conclusion</h2><h2>Image reference </h2><p>Cover: http://www.u.arizona.edu/~ppoon/qianpaper.pdf</p></div></div></div><footer id="footer"><div class="inner"><section><ul class="icons"><li><a class="icon brands style2 fa-github" href="https://github.com/Petingo"><span class="label">Github</span></a></li><li><a class="icon solid style2 fas fa-book" href="https://blog.petingo.cc"><span class="label">blog</span></a></li><li><a class="icon solid style2 fas fa-camera-retro" href="https://vsco.co/petingo"><span class="label">vsco</span></a></li><li><a class="icon brands style2 fa-instagram" href="https://instagram.com/petingo"><span class="label">Instagram</span></a></li><li><a class="icon solid style2 fa-envelope" href="mailto:eyanghongbin0315@gmail.com"><span class="label">Email</span></a></li></ul></section><ul class="copyright"><li>&copy; Petingo. All rights reserved</li><li> Modified from:<a href="https://html5up.net/phantom">HTML5 UP</a></li></ul></div></footer></div><script src="/assets/js/jquery.min.js"></script><script src="/assets/js/browser.min.js"></script><script src="/assets/js/breakpoints.min.js"></script><script src="/assets/js/util.js"></script><script src="/assets/js/main.js"></script><script src="/assets/js/ext.js"></script></body></html>